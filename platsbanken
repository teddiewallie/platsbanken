#!/bin/python

import json
import argparse
import os
import urllib.request
import datetime

today = datetime.date.today()
yesterday = today - datetime.timedelta(days=1)

today = today.strftime('%Y-%m-%d')
yesterday = yesterday.strftime('%Y-%m-%d')

adfile = 'platsbanken.json'
filterfile = 'filters.json'

parser = argparse.ArgumentParser(
        prog='Platsbanken',
        description='Curate for me')

parser.add_argument('-f', '--filter')
parser.add_argument('-u', '--update', action='store_true')
parser.add_argument('-i', '--id')
parser.add_argument('-q', '--query')
parser.add_argument('-n', '--filternames', action='store_true')
parser.add_argument('-c', '--count')
parser.add_argument('-r', '--recent', action='store_true')
parser.add_argument('--init')

args = parser.parse_args()

#
# Get raw data from json file
#
def openJson(name):
    f = open(name, 'r')
    data = json.load(f)
    f.close()
    return data

#
# Write raw data to json file
#
def dumpJson(name, dump):
    f = open(name, 'w')
    json.dump(dump, f)
    f.close()

#
# Fetch new ads from API
#
def fetch():
    joblist = openJson(adfile)
    oldcount = len(joblist)

    modified = datetime.datetime.fromtimestamp(os.path.getmtime(adfile))
    modified = modified.strftime('%Y-%m-%dT%H:%M:%S')

    url = 'https://jobstream.api.jobtechdev.se/stream?date=' + modified
    with urllib.request.urlopen(url) as stream:
        newdata = json.load(stream)
        if len(newdata) == 0:
            print('No new ads')
            return

        found = False
        for ni, no in enumerate(newdata, start=0):
            print(f"adding and updating ads: {ni}/{len(newdata) - 1}", end='\r', flush=True)
            if found == True:
                found = False
                continue

            for i, o in enumerate(joblist, start=0):
                if o['id'] == no['id']:
                    if "removed" in no and no['removed'] == True:
                        del joblist[i]
                    else:
                        joblist[i] = newdata[ni]
                    found = True

            if found == False:
                if "removed" not in no:
                    joblist.append(no)
        print()
        print(f"{len(joblist) - oldcount} new ads")
        dumpJson(adfile, joblist)

#
# Modular filter function
#
def filt(data, lamb, value):
    curatedList = []
    for idx, ad in enumerate(data):
        try:
            if lamb(ad, value) == True:
                curatedList.append(data[idx])
        except:
            continue
    return curatedList

#
# Lambdas to inject into the filter function
#
occupation = lambda ad, value: ad['occupation_group']['concept_id'] == value
municipal = lambda ad, value: ad['workplace_address']['municipality_concept_id'] == value
keyword = lambda ad, value: value in ad['description']['text']
datecheck = lambda ad, value: ad['publication_date'][:10] == value

#
# Formatted list row
#
def listRow(ad):
    return ad['publication_date'][:10] + ' ' + ad['id'] + ' ' + ad['headline']

#
# Sort list by date
#
def sortListByDate(unsortedList):
    return unsortedList.sort(key=lambda ad: ad['publication_date'])

#
# Crunch one filter
#
def crunchFilter(f):
    raw = openJson(adfile)
    curatedList = []

    if len(f['concept_ids']['workplace_address__municipality']) > 0:
        for m in f['concept_ids']['workplace_address__municipality']:
            curatedList = curatedList + filt(raw, municipal, m)
    if len(f['concept_ids']['occupation_group']) > 0:
        for m in f['concept_ids']['occupation_group']:
            if len(curatedList) == 0:
                curatedList = filt(raw, occupation, m)
            else:
                curatedList = filt(curatedList, occupation, m)

    curatedWithKeywords = []

    if len(f['keywords']['list']) > 0:
        for idx, m in enumerate(f['keywords']['list']):
            if(f['keywords']['promiscous']):
                curatedWithKeywords = curatedWithKeywords + filt(curatedList, keyword, m)
            else:
                if idx == 0:
                    curatedWithKeywords = curatedList
                curatedWithKeywords = filt(curatedWithKeywords, keyword, m)
            if idx == len(f['keywords']['list']) - 1:
                curatedList = curatedWithKeywords

    if args.recent == True:
        yesterdayAds = filt(curatedList, datecheck, yesterday)
        todayAds = filt(curatedList, datecheck, today)
        curatedList = yesterdayAds + todayAds

    sortListByDate(curatedList)

    if args.count != None:
        counter = 0;
        reverse = list(reversed(curatedList))

        while counter < int(args.count) + 1:
            print(listRow(reverse[int(args.count) - counter]))
            counter = counter + 1
        
    else:
        if len(curatedList) == 0:
            curatedList = raw
        for ad in curatedList:
            print(listRow(ad))

#
# Get filter by name
#
def getFilterByName(name):
    filters = openJson(filterfile)

    for f in filters:
        if f['name'] == name:
            return f
    return None

if args.filter != None:
    crunchFilter(getFilterByName(args.filter))

if args.update == True:
    fetch()

if args.query != None:
    keywords = args.query.split()
    raw = openJson(adfile)
    curatedList = raw
    for k in keywords:
        curatedList = filt(curatedList, keyword, k)
    sortListByDate(curatedList)
    for ad in curatedList:
        print(listRow(ad))


if args.id != None:
    raw = openJson(adfile)
    thisAd = None
    for ad in raw:
        if ad['id'] == args.id:
           thisAd = ad 
    print(thisAd['headline'])
    print(thisAd['description']['text'])

if args.filternames == True:
    filters = openJson(filterfile)
    names = ""
    for f in filters:
        names = names + f['name'] + " "
    print(names)

